{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiU07sJiY3b9",
        "outputId": "8798be79-6679-452d-8080-b093738748fe"
      },
      "outputs": [],
      "source": [
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNRBhGMnZopI"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjj77wyLZuXE"
      },
      "outputs": [],
      "source": [
        "# Unduh dan ekstrak dataset\n",
        "data_url = 'https://drive.usercontent.google.com/download?id=1T2vteOAvBrj23MK3ry_ynLWli4_gNbqe&export=download&confirm=t'\n",
        "urllib.request.urlretrieve(data_url, 'Datasets.zip')\n",
        "with zipfile.ZipFile('Datasets.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('Datasets')\n",
        "\n",
        "base_dir = 'Datasets'\n",
        "train_path = os.path.join(base_dir, 'Dataset/train')\n",
        "val_path = os.path.join(base_dir, 'Dataset/validation')\n",
        "test_path = os.path.join(base_dir, 'Dataset/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CAw6RNLaAIF",
        "outputId": "26edb892-26f5-4e15-a18b-b8cb95732be4"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator untuk training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ImageDataGenerator untuk validasi & testing\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpNr_oJcaHfn",
        "outputId": "238a6f5d-d117-4848-cb9b-16be148bb7b2"
      },
      "outputs": [],
      "source": [
        "# Load model Xception dan lakukan fine-tuning 30 layer terakhir\n",
        "pre_trained_model = Xception(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
        "for layer in pre_trained_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "for layer in pre_trained_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_layer_output = pre_trained_model.output\n",
        "print(f'Output shape of the Xception base model: {last_layer_output.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrUNgPhxaXSe",
        "outputId": "eaca0ced-58ce-49da-c65b-27829cb18bb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.4098 - loss: 1.0696\n",
            "Epoch 1: val_acc improved from -inf to 0.65101, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - acc: 0.4137 - loss: 1.0675 - val_acc: 0.6510 - val_loss: 0.9689 - learning_rate: 1.0000e-04\n",
            "Epoch 2/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.6591 - loss: 0.8575\n",
            "Epoch 2: val_acc improved from 0.65101 to 0.75503, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.6605 - loss: 0.8549 - val_acc: 0.7550 - val_loss: 0.7652 - learning_rate: 1.0000e-04\n",
            "Epoch 3/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7269 - loss: 0.6843\n",
            "Epoch 3: val_acc improved from 0.75503 to 0.78859, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.7282 - loss: 0.6820 - val_acc: 0.7886 - val_loss: 0.5970 - learning_rate: 1.0000e-04\n",
            "Epoch 4/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.7968 - loss: 0.5306\n",
            "Epoch 4: val_acc improved from 0.78859 to 0.81544, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - acc: 0.7959 - loss: 0.5307 - val_acc: 0.8154 - val_loss: 0.4915 - learning_rate: 1.0000e-04\n",
            "Epoch 5/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8094 - loss: 0.4765\n",
            "Epoch 5: val_acc improved from 0.81544 to 0.83221, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.8096 - loss: 0.4756 - val_acc: 0.8322 - val_loss: 0.4420 - learning_rate: 1.0000e-04\n",
            "Epoch 6/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8378 - loss: 0.4206\n",
            "Epoch 6: val_acc improved from 0.83221 to 0.85570, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.8374 - loss: 0.4205 - val_acc: 0.8557 - val_loss: 0.3617 - learning_rate: 1.0000e-04\n",
            "Epoch 7/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8572 - loss: 0.3476\n",
            "Epoch 7: val_acc improved from 0.85570 to 0.86577, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - acc: 0.8569 - loss: 0.3483 - val_acc: 0.8658 - val_loss: 0.3591 - learning_rate: 1.0000e-04\n",
            "Epoch 8/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8706 - loss: 0.3374\n",
            "Epoch 8: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.8707 - loss: 0.3368 - val_acc: 0.8591 - val_loss: 0.3386 - learning_rate: 1.0000e-04\n",
            "Epoch 9/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8941 - loss: 0.3139\n",
            "Epoch 9: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - acc: 0.8943 - loss: 0.3132 - val_acc: 0.8523 - val_loss: 0.3664 - learning_rate: 1.0000e-04\n",
            "Epoch 10/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.8874 - loss: 0.2724\n",
            "Epoch 10: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.8875 - loss: 0.2724 - val_acc: 0.8557 - val_loss: 0.3115 - learning_rate: 1.0000e-04\n",
            "Epoch 11/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9181 - loss: 0.2180\n",
            "Epoch 11: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.9178 - loss: 0.2187 - val_acc: 0.8490 - val_loss: 0.3431 - learning_rate: 1.0000e-04\n",
            "Epoch 12/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9127 - loss: 0.2053\n",
            "Epoch 12: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.9128 - loss: 0.2056 - val_acc: 0.8557 - val_loss: 0.4344 - learning_rate: 1.0000e-04\n",
            "Epoch 13/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9374 - loss: 0.1899\n",
            "Epoch 13: val_acc did not improve from 0.86577\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.9371 - loss: 0.1898 - val_acc: 0.8557 - val_loss: 0.4626 - learning_rate: 1.0000e-04\n",
            "Epoch 14/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9354 - loss: 0.1888\n",
            "Epoch 14: val_acc improved from 0.86577 to 0.87248, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.9354 - loss: 0.1887 - val_acc: 0.8725 - val_loss: 0.4446 - learning_rate: 1.0000e-04\n",
            "Epoch 15/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9342 - loss: 0.1557\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 15: val_acc did not improve from 0.87248\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.9340 - loss: 0.1559 - val_acc: 0.8624 - val_loss: 0.4311 - learning_rate: 1.0000e-04\n",
            "Epoch 16/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9401 - loss: 0.1636\n",
            "Epoch 16: val_acc did not improve from 0.87248\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - acc: 0.9402 - loss: 0.1632 - val_acc: 0.8557 - val_loss: 0.4005 - learning_rate: 2.0000e-05\n",
            "Epoch 17/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9568 - loss: 0.1445\n",
            "Epoch 17: val_acc did not improve from 0.87248\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - acc: 0.9570 - loss: 0.1437 - val_acc: 0.8557 - val_loss: 0.3677 - learning_rate: 2.0000e-05\n",
            "Epoch 18/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9659 - loss: 0.1104\n",
            "Epoch 18: val_acc did not improve from 0.87248\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.9659 - loss: 0.1105 - val_acc: 0.8658 - val_loss: 0.3394 - learning_rate: 2.0000e-05\n",
            "Epoch 19/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9607 - loss: 0.1152\n",
            "Epoch 19: val_acc did not improve from 0.87248\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - acc: 0.9602 - loss: 0.1164 - val_acc: 0.8725 - val_loss: 0.3185 - learning_rate: 2.0000e-05\n",
            "Epoch 20/120\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9611 - loss: 0.1265\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\n",
            "Epoch 20: val_acc improved from 0.87248 to 0.88926, saving model to Xception_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - acc: 0.9612 - loss: 0.1262 - val_acc: 0.8893 - val_loss: 0.3124 - learning_rate: 2.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Bangun model klasifikasi\n",
        "x = layers.GlobalAveragePooling2D()(last_layer_output)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=pre_trained_model.input, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('Xception_model.h5', monitor='val_acc', save_best_only=True, verbose=1)\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft3GBAX_ujPH",
        "outputId": "32561704-02f6-454b-fbc7-ba3b046d1714"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(base_dir, \"Dataset/train\")\n",
        "val_path = os.path.join(base_dir, \"Dataset/validation\")\n",
        "test_path = os.path.join(base_dir, \"Dataset/test\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "model = tf.keras.models.load_model('Xception_model.h5')\n",
        "\n",
        "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
        "val_loss, val_acc = model.evaluate(validation_generator, verbose=1)\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}, Loss: {train_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}, Loss: {val_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "ecYxaGJ6wHic",
        "outputId": "0b21c558-e338-4c40-c8c7-8ae3f1fa158e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ambil riwayat dari training\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Plot Akurasi\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Accuracy - Xception Model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Loss - Xception Model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_process_image(image_path, target_size=(299, 299)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    return img_array\n",
        "\n",
        "def load_test_data(test_dir, class_names):\n",
        "    data = []\n",
        "    labels = []\n",
        "    class_mapping = {name: idx for idx, name in enumerate(class_names)}\n",
        "    for class_name in class_names:\n",
        "        class_path = os.path.join(test_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            print(f\"Warning: Folder {class_path} not found.\")\n",
        "            continue\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            try:\n",
        "                data.append(load_and_process_image(image_path))\n",
        "                labels.append(class_mapping[class_name])\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {image_path}: {e}\")\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeoPinkjwbaw",
        "outputId": "83d72dc7-05d0-4ee0-e976-412b46fc4795"
      },
      "outputs": [],
      "source": [
        "test_data_dir = val_path\n",
        "class_names = sorted(os.listdir(test_data_dir))\n",
        "X_test, y_test = load_test_data(test_data_dir, class_names)\n",
        "\n",
        "model = keras.models.load_model('Xception_model.h5')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(to_categorical(y_test, num_classes=len(class_names)), axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "class_report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Xception Model (Validation)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report (Validation Data):\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDWqkLIqxJ-c",
        "outputId": "6b45ee48-1cc8-415b-b3ac-d97f4325dd34"
      },
      "outputs": [],
      "source": [
        "test_data_dir = train_path\n",
        "class_names = sorted(os.listdir(test_data_dir))\n",
        "X_test, y_test = load_test_data(test_data_dir, class_names)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(to_categorical(y_test, num_classes=len(class_names)), axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "class_report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Xception Model (Training)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report (Training Data):\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1PyEO1fxkL3",
        "outputId": "cec7bf81-9dd5-4088-e7bb-a8c2b677acae"
      },
      "outputs": [],
      "source": [
        "test_data_dir = test_path\n",
        "class_names = sorted(os.listdir(test_data_dir))\n",
        "X_test, y_test = load_test_data(test_data_dir, class_names)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(to_categorical(y_test, num_classes=len(class_names)), axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "class_report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Xception Model (Test)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(class_report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
